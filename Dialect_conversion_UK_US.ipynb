{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDMGnbr0H570"
      },
      "source": [
        "# **1. Data Understanding & Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3Id_bYSICuD",
        "outputId": "77316263-a133-4125-9ef2-8fe54862f410"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sacrebleu in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.5.1)\n",
            "Requirement already satisfied: portalocker in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sacrebleu) (3.1.1)\n",
            "Requirement already satisfied: regex in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sacrebleu) (2.2.0)\n",
            "Requirement already satisfied: colorama in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sacrebleu) (5.3.0)\n",
            "Requirement already satisfied: sentencepiece in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "#installing required packages\n",
        "! pip3 install sacrebleu\n",
        "! pip3 install sentencepiece\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rUctY-wEH3i7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "#import libraries\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "import sacrebleu\n",
        "import re\n",
        "\n",
        "# Set device (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeQyhzCIH3f2",
        "outputId": "74b67cfa-89d2-4dc8-c5ea-67e007d52f0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                    input_text  \\\n",
            "0  I CoLoUr üé® the centre of my favourite book.   \n",
            "1          He is travelling ‚úàÔ∏è to the THEATRE.   \n",
            "2                 I have a flat near the lift.   \n",
            "3                I have a flat near the lift.    \n",
            "4    The PROGRAMME üóìÔ∏è will start at 6 O'CLOCK.   \n",
            "\n",
            "                               target_text  \n",
            "0  I color the center of my favorite book.  \n",
            "1          He is traveling to the theater.  \n",
            "2   I have an apartment near the elevator.  \n",
            "3   I have an apartment near the elevator.  \n",
            "4     The program will start at 6 o'clock.  \n"
          ]
        }
      ],
      "source": [
        "# load dataset\n",
        "\n",
        "''' upload the data file in the files path using upload button in the colab\n",
        "also modify the file name if needed '''\n",
        "\n",
        "data_path = \"Dataset.csv\"\n",
        "df = pd.read_csv(data_path)\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "HgRRCZTDItYr",
        "outputId": "39648f40-561d-4350-dbab-cf4ecbc3dc9f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_text</th>\n",
              "      <th>target_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I colour  the centre of my favourite book</td>\n",
              "      <td>I color the center of my favorite book</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>He is travelling  to the theatre</td>\n",
              "      <td>He is traveling to the theater</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I have a flat near the lift</td>\n",
              "      <td>I have an apartment near the elevator</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I have a flat near the lift</td>\n",
              "      <td>I have an apartment near the elevator</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The programme  will start at 6 o'clock</td>\n",
              "      <td>The program will start at 6 o'clock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>The theatre's performance was breathtaking</td>\n",
              "      <td>The theater's performance was breathtaking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>Her behaviour has been commendable</td>\n",
              "      <td>Her behavior has been commendable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>The cheque was never received</td>\n",
              "      <td>The check was never received</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>The aeroplane  took off on time</td>\n",
              "      <td>The airplane took off on time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>She wears jewellery for special occasions</td>\n",
              "      <td>She wears jewelry for special occasions</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>96 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    input_text  \\\n",
              "0    I colour  the centre of my favourite book   \n",
              "1             He is travelling  to the theatre   \n",
              "2                  I have a flat near the lift   \n",
              "3                  I have a flat near the lift   \n",
              "4       The programme  will start at 6 o'clock   \n",
              "..                                         ...   \n",
              "91  The theatre's performance was breathtaking   \n",
              "92          Her behaviour has been commendable   \n",
              "93               The cheque was never received   \n",
              "94             The aeroplane  took off on time   \n",
              "95   She wears jewellery for special occasions   \n",
              "\n",
              "                                   target_text  \n",
              "0       I color the center of my favorite book  \n",
              "1               He is traveling to the theater  \n",
              "2        I have an apartment near the elevator  \n",
              "3        I have an apartment near the elevator  \n",
              "4          The program will start at 6 o'clock  \n",
              "..                                         ...  \n",
              "91  The theater's performance was breathtaking  \n",
              "92           Her behavior has been commendable  \n",
              "93                The check was never received  \n",
              "94               The airplane took off on time  \n",
              "95     She wears jewelry for special occasions  \n",
              "\n",
              "[96 rows x 2 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# clean the dataset\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Clean the input text by stripping spaces and removing emojis/extra characters.\n",
        "    Convert to lowercase to standardize.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        text = re.sub(r\"\\s+\", \" \", text.strip())\n",
        "        text = re.sub(r\"[^\\w\\s']\", \"\", text)  # Retain words, spaces, and apostrophes\n",
        "        return text[0] + text[1:].lower()\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Error cleaning text: {str(e)}\")\n",
        "\n",
        "# Clean the text in both columns\n",
        "df[\"input_text\"] = df[\"input_text\"].apply(clean_text)\n",
        "df[\"target_text\"] = df[\"target_text\"].apply(clean_text)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6yxFvJhI-10"
      },
      "source": [
        "# **2. Model Selection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ipRUuTvXH3dO"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        }
      ],
      "source": [
        "\"\"\" Model: T5 Transformer (EnglishVoice/t5-base-uk-to-us-english) from hugging face\n",
        "- T5 (Text-to-Text Transfer Transformer) is a powerful model designed for text generation tasks.\n",
        "- This pre-trained model is fine-tuned specifically for UK-to-US English conversion.\n",
        "- It is efficient and effective at handling text-based transformations.\n",
        "- Light model, can run on CPU as well.\n",
        "\"\"\"\n",
        "\n",
        "# Loading the pre-trained T5 model for UK-to-US conversion\n",
        "model_name = \"EnglishVoice/t5-base-uk-to-us-english\"\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = model.to(device)\n",
        "\n",
        "# Setting the maximum length for tokenization\n",
        "max_input_length = 64\n",
        "max_target_length = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8Oo_QSrJ45a"
      },
      "source": [
        "# **3. Model Training & Evaluation**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "5v4LUMPlJ5Zc",
        "outputId": "2d59a137-8d5a-48ef-d1b6-3393b0a96181"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample 0:\n",
            "  Input:      I colour  the centre of my favourite book\n",
            "  Target:     I color the center of my favorite book\n",
            "  Prediction: I color the center of my favorite book\n",
            "\n",
            "Sample 1:\n",
            "  Input:      He is travelling  to the theatre\n",
            "  Target:     He is traveling to the theater\n",
            "  Prediction: He is traveling to the theater\n",
            "\n",
            "Sample 2:\n",
            "  Input:      I have a flat near the lift\n",
            "  Target:     I have an apartment near the elevator\n",
            "  Prediction: I have an apartment near the elevator\n",
            "\n",
            "Sample 3:\n",
            "  Input:      I have a flat near the lift\n",
            "  Target:     I have an apartment near the elevator\n",
            "  Prediction: I have an apartment near the elevator\n",
            "\n",
            "Sample 4:\n",
            "  Input:      The programme  will start at 6 o'clock\n",
            "  Target:     The program will start at 6 o'clock\n",
            "  Prediction: The program will start at 6 o'clock\n",
            "\n",
            "Sample 5:\n",
            "  Input:      He has a cheque  for payment\n",
            "  Target:     He has a check for payment\n",
            "  Prediction: He has a check for payment\n",
            "\n",
            "Sample 6:\n",
            "  Input:      She wears jewellery  on occasions\n",
            "  Target:     She wears jewelry on occasions\n",
            "  Prediction: She wears jewelry on occasions\n",
            "\n",
            "Sample 7:\n",
            "  Input:      They are practising  for the football match\n",
            "  Target:     They are practicing for the soccer game\n",
            "  Prediction: They are practicing for the soccer match\n",
            "\n",
            "Sample 8:\n",
            "  Input:      He is using a spanner for the repair\n",
            "  Target:     He is using a wrench for the repair\n",
            "  Prediction: He is using a wrench for the repair\n",
            "\n",
            "Sample 9:\n",
            "  Input:      The aeroplane  landed on time\n",
            "  Target:     The airplane landed on time\n",
            "  Prediction: The airplane landed on time\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# create lists to save predictions and target\n",
        "predictions = []\n",
        "references = []\n",
        "\n",
        "# Loop over each row in the DataFrame to generate predictions\n",
        "for idx, row in df.iterrows():\n",
        "    input_text = row[\"input_text\"]\n",
        "    target_text = row[\"target_text\"]\n",
        "\n",
        "    # prepare the prompt expected by the model\n",
        "    prompt = \"UK to US: \" + input_text\n",
        "\n",
        "    # Tokenizing the input prompt along with input text\n",
        "    encoding = tokenizer.encode_plus(\n",
        "        prompt,\n",
        "        max_length=max_input_length,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    input_ids = encoding[\"input_ids\"].to(device)\n",
        "    attention_mask = encoding[\"attention_mask\"].to(device)\n",
        "\n",
        "    # Generate the output text\n",
        "    beam_outputs = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        num_beams=5,\n",
        "        max_length=max_target_length,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    # Decoding the output tokens to a string and clean it\n",
        "    prediction = tokenizer.decode(beam_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    predictions.append(prediction)\n",
        "    references.append(target_text)\n",
        "\n",
        "    # Printing few sample conversions\n",
        "    if idx < 10:\n",
        "        print(f\"Sample {idx}:\")\n",
        "        print(f\"  Input:      {input_text}\")\n",
        "        print(f\"  Target:     {target_text}\")\n",
        "        print(f\"  Prediction: {prediction}\")\n",
        "        print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AHqD3767J_rO",
        "outputId": "cceb0cad-760b-4701-8708-24162573a818"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Overall BLEU Score: 96.14\n",
            "Exact Match Accuracy: 94.79%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Evaluate predictions using sacrebleu\n",
        "bleu = sacrebleu.corpus_bleu(predictions, [references])\n",
        "print(f\"\\nOverall BLEU Score: {bleu.score:.2f}\")\n",
        "\n",
        "# Exact-match accuracy after cleaning predictions and references\n",
        "exact_matches = sum([1 for pred, ref in zip(predictions, references) if clean_text(pred) == clean_text(ref)])\n",
        "exact_match_accuracy = exact_matches / len(references) * 100\n",
        "print(f\"Exact Match Accuracy: {exact_match_accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBb0lNH6LxlA"
      },
      "source": [
        "# **4. Deployment & Inference**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LcTM2H0aJ_js",
        "outputId": "5b513e74-7dd6-48af-faef-1374cea3ee90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Example Inference:\n",
            "  Input:     I'm going to my flat from the theatre, let's meet for the football in the evening.\n",
            "  Converted: I'm going to my apartment from the theater, let's meet for the soccer in the evening.\n"
          ]
        }
      ],
      "source": [
        "def convert_text_uk_to_us(text):\n",
        "    \"\"\"Function to convert UK English text to US English using the trained model.\"\"\"\n",
        "\n",
        "    # cleaning and preprocessing the input text\n",
        "    cleaned_text = clean_text(text)\n",
        "\n",
        "    # prepare the prompt expected by the model\n",
        "    prompt = \"UK to US: \" + input_text\n",
        "\n",
        "    # Tokenizing the input prompt along with input text\n",
        "    encoding = tokenizer.encode_plus(\n",
        "        prompt,\n",
        "        max_length=max_input_length,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    input_ids = encoding[\"input_ids\"].to(device)\n",
        "    attention_mask = encoding[\"attention_mask\"].to(device)\n",
        "\n",
        "    # Generate the output text\n",
        "    beam_outputs = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        num_beams=5,\n",
        "        max_length=max_target_length,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    return tokenizer.decode(beam_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# inference input text, replace this with the test input\n",
        "input_text = \"I'm going to my flat from the theatre, let's meet for the football in the evening.\"\n",
        "output_text = convert_text_uk_to_us(input_text)\n",
        "\n",
        "print(f\"\\nExample Inference:\")\n",
        "print(f\"  Input:     {input_text}\")\n",
        "print(f\"  Converted: {output_text}\")  #expected output  I'm going to my apartment from the theater let's meet for the soccer in the evening"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trg2zBKYJ_ZA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
